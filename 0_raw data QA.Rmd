---
title: "Raw Data QA"
author: "Becky"
date: "August 28, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("Temp_flags_function.R")

library(rnoaa)
library(plotly)
library(readxl)
library(tidyverse)
```

# Anchor River Data


## Get Homer air temperature for checking against datasets.

```{r}


homer_air <- ghcnd_search(stationid = "USW00025507", date_min = "2010-01-01", 
                          date_max = "2019-08-31", var = "TAVG")


```


## Cook Inletkeeper

Start by plotting sites in CIK dataset separately.

```{r}

pdf("output/CIKdata.pdf", width = 11, height = 8.5)

site.year <- CIKdat %>% distinct(Site, year)

for(i in 1:37) {
  p <- CIKdat %>% 
    right_join(slice(site.year, i)) %>% 
    ggplot(aes(x = dateTime, y = Temperature)) +
    geom_line() +
    labs(title = paste0(slice(site.year, i), collapse = "_")) 
    # facet_wrap(~year, scales = "free_x")
  print(p)
}
dev.off()

```

Add temperature flags to data using temp_flags_function. Holding off on this for now because Sue gave us QAed data. Focus on APU and KBERR.


## APU Data
APU data doesn't seem like it has been completely QAed. Plot of raw data shows that sites 3 and 9 have some air temperature spikes.

```{r}

pdf("output/APUdata.pdf", width = 11, height = 8.5)

APU_sites <- APUdat %>% distinct(Site) %>% pull(Site)

for(i in APU_sites) {
  p <- APUdat %>% 
    filter(Site == i) %>% 
    ggplot(aes(x = dateTime, y = Temperature)) +
    geom_line() +
    labs(title = i) 
    # facet_wrap(~year, scales = "free_x")
  print(p)
}

p2 <- APUdat %>% 
  ggplot(aes(x = dateTime, y = Temperature)) +
  geom_line() +
  facet_wrap(~Site)
print(p2)

dev.off()

```


Add temperature flags. Can group by site since all data are from 2015.

```{r}
APU_flagged <- APUdat %>% 
  group_by(Site) %>% 
  do(add_temp_flags(.))
```

Use flag plotting function to look at flags.

```{r}
pdf("output/APUdata_wFlags.pdf")

for(i in APU_sites){
  APU_flagged %>% 
    filter(Site == i) %>% 
    plot_flags(i)
}
dev.off()

```

Plot Site 3 interactively to get dates with air temperatures. 

```{r}
p <- APU_flagged %>% 
  filter(Site == "APU3") %>% 
  ggplot(aes(x = dateTime, y = Temperature)) +
  geom_line(aes(color = flag_hourlyChange)) 

ggplotly(p) 
```


QA of flagged data:

* The hourly change flag marked some temps in late May-early June, but that pattern matches other sites (increasing then decreasing). 
* Don't use data from 6-15-2015 to 6-25-2015. Talked to Leslie and we agreed on removing this entire chunk.
* Also a couple of spikes in early July that match other sites.

```{r}
APUdat <- APUdat %>% 
  mutate(useData = ifelse((Site == "APU3" & sampleDate >= "2015-06-15" &
                               sampleDate <= "2015-06-25"), 0, 1))
```

Plot Site 9 interactively to get dates with air temperatures. 

```{r}
p <- APU_flagged %>% 
  filter(Site == "APU9") %>% 
  ggplot(aes(x = dateTime, y = Temperature)) +
  geom_line(aes(color = flag_hourlyChange)) 

ggplotly(p) 
```

QA of flagged data:

* remove 6-25-15, large anomolous spike on that date.
* remove 8-7-15, large anomolous spike on that date.
* remove 8-11 to 8-14-15.
* remove 8-23 to 9-2-15, large spikes and drops interspersed throughout this period.

```{r}
APUdat <- APUdat %>% 
  mutate(useData = case_when((Site == "APU9" & sampleDate == "2015-06-25") ~ 0,
                             (Site == "APU9" & sampleDate == "2015-08-07") ~ 0,
                             (Site == "APU9" & sampleDate >= "2015-08-11" &
                                sampleDate <= "2015-08-14") ~ 0,
                             (Site == "APU9" & sampleDate >= "2015-08-23" &
                                sampleDate <= "2015-09-02") ~ 0,
                             TRUE ~ useData))
```

Replot QAed data as a check.

```{r}

pdf("output/APUdata_postQA.pdf", width = 11, height = 8.5)
for(i in APU_sites) {
  p <- APUdat %>% 
    filter(Site == i, useData == 1) %>% 
    ggplot(aes(x = dateTime, y = Temperature)) +
    geom_line() +
    labs(title = i) 
    # facet_wrap(~year, scales = "free_x")
  print(p)
}

p2 <- APUdat %>% 
  filter(useData == 1) %>% 
  ggplot(aes(x = dateTime, y = Temperature)) +
  geom_line() +
  facet_wrap(~Site)
print(p2)

dev.off()
```




## KBERR Data

Nothing has been cleaned on the KBERR datasets, lots of air temperature in the beginning and ending of data files. May be air spikes or burials in the datasets.

Start by plotting all the data.

```{r}
load(file = "output/KBRdat.Rdata")

pdf("output/KBRdata.pdf", width = 11, height = 8.5)

site.year <- KBRdat %>% distinct(Site, year)

for(i in 1:53) {
  p <- KBRdat %>% 
    right_join(slice(site.year, i)) %>% 
    ggplot(aes(x = dateTime, y = Temperature)) +
    geom_line() +
    labs(title = paste0(slice(site.year, i), collapse = "_")) 
  print(p)
}
dev.off()


```

Add temperature flags. Group by file so that each data group is continuous.

```{r}
KBRdat <- KBRdat %>% 
  group_by(fileName) %>% 
  do(add_temp_flags(.)) %>% 
  ungroup()
```

Use flag plotting function to look at flags.

```{r}
pdf("output/KBRdata_wFlags.pdf")

for(i in 1:53){
  dat <- KBRdat %>% 
    right_join(slice(site.year, i)) 
  plotTitle <- paste0(slice(site.year, i), collapse = "_")
  plot_flags(dat, plotTitle)
}
dev.off()

```

Plot sites interactively to get dates with air temperatures. Can probably plot by site only since plotly enables easy zooming. If there are lots of bad data for any sites from 2008, can import data from surface logger to see if it is better. 

```{r}

# plot_hourly_flag_interactively <- function(data, site) {
#   p <- data %>% 
#   filter(Site == site) %>% 
#   ggplot(aes(x = dateTime, y = Temperature)) +
#   geom_line(aes(linetype = as.factor(flag_hourlyChange), color = fileName)) +
#   labs(title = site)
#   ggplotly(p) 
#   
#   dat <- KBRdat %>% filter(Site == site)
#   minDatetime <- dat %>% distinct(dateTime) %>% pull(dateTime) %>% min 
#   maxDatetime <- dat %>% distinct(dateTime) %>% pull(dateTime) %>% max 
#   allDate <- tibble(dateTime = seq.POSIXt(from = as.POSIXct(minDatetime), to = as.POSIXct(maxDatetime), by = 900))
#   noflag <- left_join(allDate, dat %>% filter(flag_hourlyChange == 0) %>% select(dateTime, Temperature, fileName))
#   yesflag <- left_join(allDate, dat %>% filter(flag_hourlyChange == 1) %>% select(dateTime, Temperature, fileName))
#   p <- ggplot() +
#     geom_line(data = noflag, aes(x = dateTime, y = Temperature, color = fileName), linetype = 1) +
#     geom_line(data = yesflag, aes(x = dateTime, y = Temperature, color = fileName), linetype = 2) +
#     labs(title = site)
#   ggplotly(p)
# }


plot_hourly_flag_interactively <- function(data, site) {
  p <- data %>%
  filter(Site == site) %>%
  ggplot(aes(x = dateTime, y = Temperature)) +
  geom_line(aes(color = fileName)) +
  labs(title = site)
  ggplotly(p)
}
```

Plot data interactively (below) and enter all the dates used for flagging bad data into Excel (much easier than typing in R). Deployment date for each file, retrieval data for each file, and air temperature dates.

```{r}
sites <- KBRdat %>% distinct(Site) %>% arrange(Site) %>% pull(Site)

siteIn <- sites[11]
print(siteIn)

plot_hourly_flag_interactively(KBRdat, siteIn) 

p <- ggplot() +
  geom_line(data = KBRdat %>% filter(Site == "COTT-W"), aes(x = dateTime, y = Temperature, color = fileName)) +
  geom_line(data = KBRdat %>% filter(Site == "COTT-C"), aes(x = dateTime, y = Temperature, color = fileName))

ggplotly(p)

```

Create useData field and flag bad data as 0. 

* temperatures < -1.
* deployment date - all dates on or before this date are flagged for removal.
* retrieval date - all dates on or after this date are flagged for removal.
* air temperature date - all dates are flagged for removal.
* remove duplicate loggers that are not needed.

```{r}

KBR_dates_for_flagging <- read_excel("Data/RAW Data/Anchor/KBERR/KBERR_QA_air_temps.xlsx", 
                                     sheet = "air temperature dates", col_names = TRUE,
                                     col_types = c("text", "text", "date"))


KBRdat <- KBRdat %>% 
  mutate(useData = ifelse(Temperature < -1, 0, 1))

for (i in 1:dim(KBR_dates_for_flagging)[1]) {
  flag <- slice(KBR_dates_for_flagging, i)
  KBRdat <- KBRdat %>% 
    mutate(useData = case_when(Site == flag$Site & flag$flag_type == "deployment" & 
                                 sampleDate <= flag$flag_date ~ 0,
                               Site == flag$Site & flag$flag_type == "retrieval" & 
                                 sampleDate >= flag$flag_date ~ 0,
                               Site == flag$Site & flag$flag_type == "air temperature" & 
                                 sampleDate == flag$flag_date ~ 0,
                               TRUE ~ useData))
}

```

Remove duplicate loggers.

```{r}
KBR_remove_dups <- read_excel("Data/RAW Data/Anchor/KBERR/KBERR_QA_air_temps.xlsx", 
                                     sheet = "duplicate loggers", col_names = TRUE)

KBRdat <- KBRdat %>% 
  filter(!fileName %in% (KBR_remove_dups %>% pull(fileName)))

```

Replot all sites and make sure that air temperatures are now removed.
Everything looks good (9/25/19)

```{r}

pdf("output/KBRdata_postQA.pdf", width = 11, height = 8.5)
for(i in sites) {
  p <- KBRdat %>% 
    filter(useData == 1, Site == i) %>% 
    ggplot(aes(x = dateTime, y = Temperature)) +
    geom_line(aes(color = fileName)) +
    labs(title = i) 
  print(p)
}
dev.off()


```

Since combining loggers, check that there are no duplicate data that I didn't catch. All clear!

```{r}
KBRdat %>% filter(useData == 1) %>% 
  distinct(Site, fileName, sampleDate) %>% count(Site, sampleDate) %>% filter(n > 1)
```









## Save QAed data for import into database

Tried combining all three Anchor datasets and importing to mysql database, but timeout error. Instead, add locationid to each file separately, save as a data file and import.


```{r}

db_locTbl <- read_csv("D:/AKNHP/Temperature_Data/Database/Import files/location.csv")

CIKdat %>%
  mutate(useData = 1) %>% 
  left_join(db_locTbl %>% select(ACCS_siteid, loc_id), by = c("Site" = "ACCS_siteid"))  %>%
  select(date = sampleDate,
         time = sampleTime,
         temperature = Temperature,
         use_data = useData,
         location_id = loc_id) %>% 
  write.csv(., file = "D:/AKNHP/Temperature_Data/Database/Import files/cik_anchor_data.csv")
  
APUdat %>%
  filter(useData == 1) %>% 
  left_join(db_locTbl %>% select(ACCS_siteid, loc_id), by = c("Site" = "ACCS_siteid"))  %>%
  select(date = sampleDate,
         time = sampleTime,
         temperature = Temperature,
         use_data = useData,
         loc_id) %>% 
  write.csv(., file = "D:/AKNHP/Temperature_Data/Database/Import files/apu_anchor_data.csv")

KBRdat %>%
  filter(useData == 1) %>% 
  left_join(db_locTbl %>% select(contact_siteid, loc_id), by = c("Site" = "contact_siteid"))  %>%
  select(date = sampleDate,
         time = sampleTime,
         temperature = Temperature,
         use_data = useData,
         loc_id) %>% 
  write.csv(., file = "D:/AKNHP/Temperature_Data/Database/Import files/kbr_anchor_data.csv")




```

