---
title: "8_Data Catalog files"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(tidyverse)
library(sf)
library(lubridate)

options(scipen = 999)
```

This is for documenting the files that will go on the ACCS Data Catalog. 

1. sites: lat, long, agency id, catchment id, used in model 
2. temperature data: raw data being formatted for upload to AKTEMP
3. spatial predictor variables: catchment id, reach_slope, catchment_elev_mn, cont_area, ca_elev_mn, wetland, forest (glacier and lake for Kenai only)
4. climate predictor variables: catchment id, date, tair3, prcp5, sweA1
5. predictions: catchment id, date, predicted mean daily stream temp
6. future predictions: catchment id, scenario, predicted mean daily stream temp
7. historic temperature metrics: catchment id, year, metric, value
8. future temperature metrics: catchment id, scenario, metric, value


# Shapefiles - catchments and flowlines

Reading in from feature gdb and saving as shapefiles.

Adding correct awc information to catchments. 

``` {r}
fgdb <- "W:/GIS/Anchor/Anchor_spatial.gdb"
fl <- sf::st_read(dsn = fgdb, layer = "anch_rca_reaches_attributed_03112020")
fl <- st_zm(fl)
cat <- sf::st_read(dsn = fgdb, layer = "anchor_rcas_attributed_06022020")
cat <- st_zm(cat)
#currently epsg 3338, nad83/ak albers

ggplot() +
  geom_sf(data = cat, fill = NA) +
  geom_sf(data = fl, color = "blue")
```
save flowlines and catchments as shapefiles. 

```{r}

#read in new file with awc attributes on catchments, these were edited on 9/12/20
cat_spp <- read_excel("Data/anchor_rcas_awc_updated_091220.xls")

anchor_catchments <- cat %>% 
  rename(catchmentID = rca_id) %>% 
  select(catchmentID, HUC12, HUC_name)

anchor_fl <- fl %>% 
  select(catchmentID = reach_id)

anchor_catchments <- merge(anchor_catchments, cat_spp %>% select(catchmentID = rca_id, K_s, CO_s, K_r, CO_r))

st_write(anchor_catchments, "output/data_catalog/anchor_catchments.shp", append = FALSE, delete_layer = TRUE)

st_write(anchor_fl, "output/data_catalog/anchor_flowlines.shp", append = FALSE, delete_layer = TRUE)
```


# Tables

1. sites: lat, long, agency id, catchment id, used in model 

Used rca_join table to get site ids that can link to the data file and also lat/longs and rca ids. Need to manually set a useSite field for the 7 sites that were not included in the analysis.

```{r}
rca_join <- read_excel("Data/anchor_sites_rcas.xlsx")
rca_join <- rca_join %>% 
  mutate(Site_join = case_when(contact_id == 2 ~ contact_siteid,
                               contact_id != 2 ~ accs_siteid)) %>% 
  filter(!(grepl("DEEP", contact_siteid) | grepl("NINI", contact_siteid))) %>% 
  rename(SiteID = Site_join, catchmentID = rca_id) %>% 
  select(SiteID, catchmentID, latitude, longitude)

rca_join

# temp.rca <- rca_join %>% 
#   dplyr::select(Site_join, rca_id) %>% 
#   right_join(temp, by = c("Site_join" = "Site")) %>% 
#   rename(Site = Site_join)
  

anchor_sites_tbl <- rca_join %>% 
  mutate(useSite = case_when(SiteID %in% c("NANC-44-M", "NANC-44-U", "STAR-69-M", "STAR 171 Lower", "SANC-1203-U", "APU10", "APU1") ~ 0,
                             TRUE ~ 1))
    
anchor_sites_tbl %>% count(useSite)
anchor_sites_tbl %>% arrange(SiteID)

anchor_sites_tbl %>% write_csv("output/data_catalog/anchor_sites.csv")

```

2. temperature data: raw data being formatted for upload to AKTEMP

This was already created in 1_create model data frame script. Loaded rds with raw data, which includes all 51 sites. Removed 8 sites not in Anchor-Stariski. Note that I am flagging this all as useDate == 1. These came from final datasets that were filtered to only include good data. This seems fine for this archive. For AKTEMP will include all raw data and bad data as 0s.


```{r}

temp_subdaily <- readRDS("output/temp.rds")

temp_subdaily %>% distinct(Site)

temp_subdaily %>% filter(Site %in% c("APU1", "APU10")) %>% distinct(Site, year)

anchor_temperature_data <- temp_subdaily %>% 
  rename(SiteID = Site) %>% 
  filter(!(grepl("DEEP", SiteID) | grepl("NINI", SiteID))) %>% 
  mutate(useData = 1) %>% 
  select(SiteID, sampleDate, sampleTime, Temperature, useData)

anchor_temperature_data %>% distinct(SiteID)

anchor_temperature_data %>% write_csv("output/data_catalog/anchor_temperature_data.csv")

```

3. spatial predictor variables: catchment id, reach_slope, catchment_elev_mn, cont_area, ca_elev_mn, wetland, forest (glacier and lake for Kenai only)

Read in covariates associated with the flowlines and catchments in the geodatabase. 

Merge attributes for all to the new data frame. Use the flowacc value and convert to square kilometers. (The cont_area is the flow accumulation multiplied by 25 and converted from square meters to square kilometers.)

```{r}

anchor_spatial_variables <- fl %>% 
  st_set_geometry(NULL) %>% 
  select(catchmentID = reach_id, reach_slope, Forest, Wetland) 

anchor_spatial_variables <- cat %>% 
  st_set_geometry(NULL) %>% 
  select(catchmentID = rca_id, catchment_elev_mn = rca_elev_mn, flowacc, ca_elev_mn) %>% 
  mutate(cont_area = flowacc * 25 / 1000000) %>% 
  right_join(anchor_spatial_variables)


anchor_spatial_variables %>% 
  select(-flowacc) %>% 
  write_csv("output/data_catalog/anchor_spatial_variables.csv")

```

4. climate predictor variables: catchment id, date, tair3, prcp5, sweA1

Read in climate covariates generated in KFHP repo that were calculated for the RCAs. These are tables that have climate information linked to the RCAs and that have been copied over the data/daymet folder.

Start with the daymet data: air, precipitation, and SWE. We are now moving forward with 3-day averaged air temperatures. The daymet date represents the middle day.

```{r}
fgdb <- "W:\\Leslie\\GIS\\KFHP\\Geodatabase\\anchor_DAYMET.gdb"
tair <- sf::st_read(dsn = fgdb, layer = "tair3_anchor_all")

tair_tbl <- tair %>%
  mutate(date = as.Date(date),
         sampleDate = date + 1) %>% 
  select(catchmentID = rca_id, sampleDate, tair3)

tair_tbl
```

Read in the precipitation file with data from 1980 - 2018. Note: Daymet is middle of 5-day window. We want daymet to represent day of and four days prior for modeling daily stream temperatures.

```{r}
prcp5day <- sf::st_read(dsn = fgdb, layer = "prcp5day")

prcp_tbl <- prcp5day %>% 
  mutate(date = as.Date(date),
         sampleDate = date + 2) %>% 
  select(catchmentID = rca_id, sampleDate, prcp5)

prcp_tbl
```

Read in the SWE file with data from 1980 - 2018. Add year for merging.

```{r}
swe <- read_csv("Data/sweA1_anchor.csv")
swe_tbl <- swe %>% 
  mutate(year = year(date)) %>% 
  select(catchmentID = rca_id, sampleDate = date, year, sweA1)

swe_tbl
```

Merge all tair and prcp together. Provide swe separately since by year and for april 1, which isn't in the prcp or air data.

```{r}
anchor_climate_variables <- left_join(tair_tbl, prcp_tbl) 

anchor_climate_variables %>% 
  write_csv("output/data_catalog/anchor_climate_variables.csv")

swe_tbl %>% 
  write_csv("output/data_catalog/anchor_swe_variable.csv")
```

5. predictions: catchment id, date, predicted mean daily stream temp

Note that even though catchment id is text in this data frame (after paste function), it still writes as a number to csv and shows up in excel with scientific notation. Just need a note that they have to be converted to numeric to see everything.

```{r}
anchor_predictions <- readRDS(file = "output/preds.rds")

anchor_predictions %>%
  select(catchmentID = reach_id, date, predict_temp = predict.HUC_name) %>% 
  write_csv("output/data_catalog/anchor_predictions.csv")
```

6. future predictions: catchment id, scenario, predicted mean daily stream temp

```{r}
anchor_future_predictions <- readRDS(file = "output/preds_fut2.rds")

anchor_future_predictions %>%
  mutate(fakedate = as.Date(day, origin = "2020-01-01"),
         date = format(fakedate, "%m-%d")) %>% 
  select(catchmentID = reach_id, jd = day, date, scenario, predict_temp = predict.HUC_name) %>% 
  write_csv("output/data_catalog/anchor_future_predictions.csv")

```

7. historic temperature metrics: catchment id, year, metric, value

```{r}
anchor_metrics <- readRDS(file = "output/mets.rds")

anchor_metrics %>% 
  ungroup() %>% 
  select(catchmentID = reach_id) %>% 
  write_csv("output/data_catalog/anchor_metrics.csv")

```


8. future temperature metrics: catchment id, scenario, metric, value


```{r}
anchor_future_metrics <- readRDS(file = "output/mets_fut.rds")

anchor_future_metrics %>% 
  ungroup() %>% 
  select(catchmentID = reach_id, scenario, June_mn:Aug_mn) %>% 
  write_csv("output/data_catalog/anchor_future_metrics.csv")

```

